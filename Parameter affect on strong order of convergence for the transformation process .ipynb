{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m\n",
    "from scipy.stats import linregress # used to get the linear parameters from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function will compute the strong error for the implicit EM approximation of the Lamperti transformation\n",
    "# The Milstein approximation of the SABR model will be used as the reference solution to calculate strong error\n",
    "def Implicit(T, N, sig_0, M, alpha, Y_0, rho, theta):\n",
    "    # sig_0 = sigma(0)\n",
    "    dt = T/N # step size\n",
    "    Milstein_N = 2**18 # Number of steps for reference solution\n",
    "    Y_n = np.ones(M)*Y_0 # array to hold values for Y at t for each monte carlo simulation\n",
    "    sig_t = np.ones(M)*sig_0 # array to hold values for sigma at t for each monte carlo simulation\n",
    "    F_0 = (Y_0 * (1 - theta))**(1/(1 - theta)) # convert Y(0) to F(0)\n",
    "    Mil = np.ones(M)*F_0 # array to hold values for Milstein at t for each monte carlo simulation\n",
    "    A = np.array([alpha*rho, alpha*np.sqrt(1 - rho**2)]) # Cholesky factor\n",
    "    dt_mil = T/Milstein_N # step size for reference solution\n",
    "    B = np.zeros(M) # empty array to hold cumulative Brownian motion\n",
    "    B1_Y = np.zeros(M) # empty array to hold Brownian motion\n",
    "    for i in range(Milstein_N):\n",
    "        Z = np.sqrt(dt_mil) * np.random.normal(0, 1, (2, M)) # calculate Brownian increment for B1 and B2\n",
    "        B += Z[0,:] # cumulate the Brownian increment for B1\n",
    "        B2 = A[0]*Z[0,:] + A[1]*Z[1,:]  # Brownian motion for B2 in the reference solution\n",
    "        B1 = Z[0, :] # Brownian motion for B1 in the reference solution\n",
    "        sig_t = sig_t*np.exp((-alpha**2 / 2)*dt_mil + B2) # sigma(t)\n",
    "        Mil = Mil + sig_t*B1*np.abs(Mil)**theta +\\\n",
    "            0.5*(sig_t**2)*theta*(B1**2 - dt_mil)*np.abs(Mil)**(2*theta - 1) # Milstein approximation\n",
    "        \n",
    "        # to keep on the same path, Yn will be calculated when the below condition is true\n",
    "        if (i+1)%(Milstein_N//N) == 0:\n",
    "            Y_n = ((Y_n + sig_t*(B-B1_Y))/2) + \\\n",
    "                np.sqrt((((Y_n + sig_t*(B-B1_Y))**2)/4) - (dt * theta * sig_t**2) / (2 * (1 - theta))) # Yn\n",
    "            B1_Y = np.copy(B) # Store the cumulative Brownian motion for B1\n",
    "    \n",
    "    F_n = (Y_n * (1 - theta))**(1/(1 - theta)) # convet Yn to Fn\n",
    "    return F_n, Mil # Return the values when n=N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha affect on strong order of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1 # time\n",
    "rho = 0.25 # correlation between B1 and B2\n",
    "M=10**3 # No. of Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.array([0.01, 0.0125, 0.025, 0.0375, 0.05, 0.075, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]) # values of alpha that will be evaluated\n",
    "thetaSim = np.array([0.5, 0.6, 0.7, 0.8, 0.9]) # range theta that will be evaluated\n",
    "Nsteps = np.array([ 2**6, 2**8, 2**9, 2**10, 2**12]) # Range of step sizes\n",
    "Alpha_error = np.zeros((len(alpha), len(Nsteps), len(thetaSim)))\n",
    "for k in range(len(alpha)):\n",
    "    for i in range(len(Nsteps)):\n",
    "        for j in range(len(thetaSim)):\n",
    "            F_T, Mil= Implicit(T=T, N=Nsteps[i], M=M, sig_0=0.05, alpha=alpha[k], Y_0=10, rho=rho, theta=thetaSim[j])\n",
    "            Alpha_error[k,i,j] = np.mean(np.abs(Mil - F_T)) # Strong error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation for the strong order of convergence, gamma, and C\n",
    "Dt = T / Nsteps\n",
    "gamma_array = np.zeros((len(alpha), len(thetaSim)))\n",
    "for j in range(len(alpha)):         \n",
    "    for i in range(len(thetaSim)):\n",
    "        Mil_gamma, Mil_C = linregress(np.log(Dt), np.log(Alpha_error[j, :,i]))[0:2]\n",
    "        C_Mil = m.exp(Mil_C)\n",
    "        gamma_array[j, i] = Mil_gamma\n",
    "        print('For the Milstein method, when theta={}, , alpha = {}, gamma = {} and C = {}\\n'.format(round(thetaSim[i],1), alpha[j], Mil_gamma, C_Mil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(alpha, gamma[:, 4],'x', linestyle='--', label='theta={}'.format(round(thetaSim[4], 1)))\n",
    "plt.plot(alpha, gamma[:, 5],'d', linestyle='--', label='theta={}'.format(round(thetaSim[5], 1)))\n",
    "plt.plot(alpha, gamma[:, 6],'o', linestyle='--', label='theta={}'.format(round(thetaSim[6], 1)))\n",
    "plt.plot(alpha, gamma[:, 7],'s', linestyle='--', label='theta={}'.format(round(thetaSim[7], 1)))\n",
    "plt.plot(alpha, gamma[:, 8],'*', linestyle='--', label='theta={}'.format(round(thetaSim[8], 1)))\n",
    "plt.legend(fontsize=14, ncol=2)\n",
    "plt.xlabel(r'$\\alpha$', fontsize=22)\n",
    "plt.ylabel('Order of convergence', fontsize=18)\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "plt.grid()\n",
    "# plt.savefig('alpha_transformation.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rho affect on strong order of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1 # time\n",
    "alpha = 0.5 # alpha coefficient in the SABR model\n",
    "M=10**3 # No. of Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = np.array([-1, -0.67, -0.33, 0, 0.33, 0.67, 1]) # rho values that will be evaluated\n",
    "thetaSim = np.array([0.5, 0.6, 0.7, 0.8, 0.9]) # range theta that will be evaluated\n",
    "Nsteps = np.array([ 2**6, 2**8, 2**9, 2**10, 2**12]) # Range of step sizes\n",
    "rho_error = np.zeros((len(rho), len(Nsteps), len(thetaSim)))\n",
    "for k in range(len(rho)):\n",
    "    for i in range(len(Nsteps)):\n",
    "        for j in range(len(thetaSim)):\n",
    "            F_T, Mil= Implicit(T=T, N=Nsteps[i], M=M, sig_0=0.2, alpha=alpha, Y_0=10, rho=rho[k], theta=thetaSim[j])\n",
    "            rho_error[k,i,j] = np.mean(np.abs(Mil - F_T)) # Strong error for Milstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation for the strong order of convergence, gamma, and C\n",
    "Dt = T / Nsteps\n",
    "gamma_array_rho = np.zeros((len(rho), len(thetaSim)))\n",
    "for j in range(len(rho)):         \n",
    "    for i in range(len(thetaSim)):\n",
    "        Mil_gamma, Mil_C = linregress(np.log(Dt), np.log(rho_error[j, :,i]))[0:2]\n",
    "        C_Mil = m.exp(Mil_C)\n",
    "        gamma_array_rho[j, i] = Mil_gamma\n",
    "        print('For the Milstein method, when theta={}, , rho = {}, gamma = {} and C = {}\\n'.format(round(thetaSim[i],1), rho[j], Mil_gamma, C_Mil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(rho, gamma_array_rho[:, 4],'x', linestyle='--', label='theta={}'.format(round(thetaSim[4], 1)))\n",
    "plt.plot(rho, gamma_array_rho[:, 5],'d', linestyle='--', label='theta={}'.format(round(thetaSim[5], 1)))\n",
    "plt.plot(rho, gamma_array_rho[:, 6],'o', linestyle='--', label='theta={}'.format(round(thetaSim[6], 1)))\n",
    "plt.plot(rho, gamma_array_rho[:, 7],'s', linestyle='--', label='theta={}'.format(round(thetaSim[7], 1)))\n",
    "plt.plot(rho, gamma_array_rho[:, 8],'*', linestyle='--', label='theta={}'.format(round(thetaSim[8], 1)))\n",
    "plt.legend(fontsize=14, ncol=2)\n",
    "plt.xlabel(r'$\\rho$', fontsize=22)\n",
    "plt.ylabel('Order of convergence', fontsize=18)\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "plt.grid()\n",
    "# plt.savefig('rho_transformation.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigma(0) affect on strong order of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1 # time\n",
    "alpha = 0.01 # alpha coefficient in the SABR model\n",
    "rho = 0.25 # correlation between B1 and B2\n",
    "M=10**3 # No. of Monte Carlo Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_0 = np.array([0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]) # range of sigma(0) values to be evaluated\n",
    "thetaSim = np.array([0.5, 0.6, 0.7, 0.8, 0.9]) # range theta that will be evaluated\n",
    "Nsteps = np.array([ 2**6, 2**8, 2**9, 2**10, 2**12]) # Range of step sizes\n",
    "sig_0_error = np.zeros((len(sig_0), len(Nsteps), len(thetaSim)))\n",
    "for k in range(len(sig_0)):\n",
    "    for i in range(len(Nsteps)):\n",
    "        for j in range(len(thetaSim)):\n",
    "            F_T, Mil= Implicit(T=T, N=Nsteps[i], M=M, sig_0=sig_0[k], alpha=alpha, Y_0=10, rho=rho, theta=thetaSim[j])\n",
    "            sig_0_error[k,i,j] = np.mean(np.abs(Mil - F_T)) # Strong error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation for the strong order of convergence, gamma, and C\n",
    "Dt = T / Nsteps\n",
    "gamma_array_sig_0 = np.zeros((len(sig_0), len(thetaSim)))\n",
    "for j in range(len(sig_0)):         \n",
    "    for i in range(len(thetaSim)):\n",
    "        Mil_gamma, Mil_C = linregress(np.log(Dt), np.log(sig_0_error[j, :,i]))[0:2]\n",
    "        C_Mil = m.exp(Mil_C)\n",
    "        gamma_array_sig_0[j, i] = Mil_gamma\n",
    "        print('For the Milstein method, when theta={}, , sig_0 = {}, gamma = {} and C = {}\\n'.format(round(thetaSim[i],1), sig_0[j], Mil_gamma, C_Mil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(sig_0, gamma[:, 4],'x', linestyle='--', label='theta={}'.format(round(thetaSim[4], 1)))\n",
    "plt.plot(sig_0, gamma[:, 5],'d', linestyle='--', label='theta={}'.format(round(thetaSim[5], 1)))\n",
    "plt.plot(sig_0, gamma[:, 6],'o', linestyle='--', label='theta={}'.format(round(thetaSim[6], 1)))\n",
    "plt.plot(sig_0, gamma[:, 7],'s', linestyle='--', label='theta={}'.format(round(thetaSim[7], 1)))\n",
    "plt.plot(sig_0, gamma[:, 8],'*', linestyle='--', label='theta={}'.format(round(thetaSim[8], 1)))\n",
    "plt.legend(fontsize=14, ncol=2)\n",
    "plt.xlabel(r'$\\sigma (0)$', fontsize=22)\n",
    "plt.ylabel('Order of convergence', fontsize=18)\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "plt.grid()\n",
    "# plt.savefig('sigma_0_transformation.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
